{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4f8e7-e901-462a-b7af-d05bec712b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dcf00-8793-401a-92b7-63f671a65263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe from csv file\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "df = pd.read_csv(cwd+\"/BA_reviews.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783226b-cee4-4388-8c81-d0d5fd117d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7efc03-b0aa-4a0b-b4d9-a7e332c6ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also create a column which mentions if the user is verified or not.\n",
    "\n",
    "df['verified'] = df.reviews.str.contains(\"Trip Verified\")\n",
    "df['verified']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23238b00-5996-40d6-8a90-789406683578",
   "metadata": {},
   "source": [
    "Cleaning Reviews\n",
    "We will extract the column of reviews into a separate dataframe and clean it for semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7f8b8-819c-4fcd-8c85-59d06562eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for lemmatization of words we will use nltk library\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "reviews_data = df.reviews.str.strip(\"âœ… Trip Verified |\")\n",
    "\n",
    "#create an empty list to collect cleaned data corpus\n",
    "corpus =[]\n",
    "\n",
    "#loop through each review, remove punctuations, small case it, join it and add it to corpus\n",
    "for rev in reviews_data:\n",
    "    rev = re.sub('[^a-zA-Z]',' ', rev)\n",
    "    rev = rev.lower()\n",
    "    rev = rev.split()\n",
    "    rev = [lemma.lemmatize(word) for word in rev if word not in set(stopwords.words(\"english\"))]\n",
    "    rev = \" \".join(rev)\n",
    "    corpus.append(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadac6e-bc85-49fb-92ac-2db718201385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the corpus to the original dataframe\n",
    "\n",
    "df['corpus'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61eac9-9a40-4a2b-a00f-af4e3800fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84028433-84c0-483f-ac22-ad5680e2bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning/Fromat date\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80d101-c65b-4caa-ba99-a3ae67c9d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date to datetime format\n",
    "\n",
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8df23-8db9-4220-a235-c3f354c3c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894dcc1-26f6-468d-a261-cef050d8f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning ratings with stars\n",
    "#check for unique values\n",
    "df.stars.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a23d7-62aa-4d75-b001-1dc19fa2b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \\t and \\n from the ratings\n",
    "df.stars = df.stars.str.strip(\"\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46975d-aceb-49e3-9627-9a1cb9902150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f0c35-455f-40b6-a6b6-47a689bb681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows where the value of ratings is None\n",
    "df.drop(df[df.stars == \"None\"].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ca951-26ef-4292-881c-50840bc47707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the unique values again\n",
    "df.stars.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5875cab-a721-46a2-a725-9c10b2712652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null Values\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053efe43-5b6b-4b0b-88ad-18f983249c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3ad47-3886-45a3-b3e8-bd7bc270540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows using index where the country value is null\n",
    "df.drop(df[df.country.isnull() == True].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a86e57-927e-40f2-907c-732fcfd599f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c6e4c-2528-4017-9459-d94fb1980d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting the index\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e0c29-b83d-482f-992f-add8edb91594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned data\n",
    "\n",
    "df.to_csv(cwd + \"/cleaned-BA-reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
